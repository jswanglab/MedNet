{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 誘導式深度學習 (Highlighted DL) 效果在 TensorFlow + Keras 上的實證"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 實驗背景\n",
    "　　這是基於我的碩士論文「以誘導式深度學習為基礎之配藥核實技術及應用」所延伸的實驗（多國發明專利申請中，論文未公開）。在原始論文裡，我採用了 YOLO v2、ResNet 與 SE-ResNet 三種網路，證明「誘導式深度學習」能有效解決**訓練樣本稀少**、**藥物外觀相似**與**藥物種類繁多**等藥物識別上的難題，不但將藥物辨識率從 86% 提升至 99.8%，更採用 NVIDIA® Jetson TX2 嵌入式系統與模型結構優化技術，實現 6.23 幀 / 秒的實時藥物識別產品雛型。\n",
    "\n",
    "　　由於 YOLO v2、ResNet 與 SE-ResNet 皆屬較龐大的網路，所以，為了證明「誘導式深度學習」在簡單的 CNN 網路上**也能有卓越的識別率優化效果**，我將使用論文中未出現的 TensorFlow 與 Keras 框架重新進行實驗，也就是接下來這份文件中的內容。\n",
    "\n",
    "\n",
    "### 數據說明\n",
    "　　這項實驗所採用的數據與原始論文相同：成人錠劑**排藥包裝 (Blister Package)** 共 250 類，每個類別正、反面各 72 張，總計 36,000 張影像。對了！這是一份公開數據集，您可以在 [Google Drive](https://drive.google.com/folderview?id=1cV7JVYGRxcm9DY0o7BMJHTCRdo_RW17n) 或 [Baidu Pan](https://pan.baidu.com/s/1amfARVIhGIfYVIIfB9qFRg) 下載，供學術研究與非商業性質的實驗使用。\n",
    "\n",
    "\n",
    "### 實驗說明\n",
    "　　與原始論文相同，我將使用排藥的 **1. 正面原始影像**、**2. 背面原始影像**，與經過「誘導式深度學習」技術生成的 **3. 雙面拼整影像**資料集，對相同的 CNN 網路進行訓練與測試，目的在於觀察「誘導式深度學習」技術的採用與否，對排藥識別效果的影響會有多大。\n",
    "  \n",
    "　　在訓練樣本、測試樣本的分配上，將依照 3:1 的比例，對每類別 72 張圖像**隨機抽取** 54 張作為訓練集 (Training-set)、18 張作為測試集 (Testing-set)，總計訓練樣本 13,500 張，訓練樣本外 (Out-of-sample) 的測試樣本 4,500 張。訓練時，還會從每類別 54 張訓練圖像中再**隨機抽取** 18 張作為驗證集 (Validation-set)。\n",
    "  \n",
    "　　介紹完了，我們開始吧！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. 環境參數設定\n",
    "設置載入的套件與資料集路徑。在本實驗中，我將採用 150 x 150 的圖像輸入尺寸進行模型的訓練與測試，而非原始論文的 224 x 224。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras.layers.core import Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "image_size = 150\n",
    "\n",
    "# 正面原始影像的訓練與測試圖像路徑。\n",
    "front_train_dir = \"/home/ubuntu/Desktop/High/OriginalFrontTrain\"\n",
    "front_test_dir = \"/home/ubuntu/Desktop/High/OriginalFrontTest\"\n",
    "\n",
    "# 背面原始影像的訓練與測試圖像路徑。\n",
    "back_train_dir = \"/home/ubuntu/Desktop/High/OriginalBackTrain\"\n",
    "back_test_dir = \"/home/ubuntu/Desktop/High/OriginalBackTest\"\n",
    "\n",
    "# 雙面拼整影像的訓練與測試圖像路徑。\n",
    "high_train_dir = \"/home/ubuntu/Desktop/High/HighlightedTrain\"\n",
    "high_test_dir = \"/home/ubuntu/Desktop/High/HighlightedTest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. 建立簡單的 CNN 模型（三種資料集都使用相同的模型結構）\n",
    "卷積神經網路中採用 Dropout 防止數據過擬合；最後一個全連接層使用 Softmax 作為激活函數，對 250 種排藥類別進行預測。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 148, 148, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 74, 74, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 74, 74, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 72, 72, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 15, 15, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               401536    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 250)               32250     \n",
      "=================================================================\n",
      "Total params: 494,298\n",
      "Trainable params: 494,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 訓練與識別正面原始影像的模型\n",
    "model_front = models.Sequential()\n",
    "model_front.add(layers.Conv2D(16, (3, 3), activation = 'relu', input_shape = (image_size, image_size, 3)))\n",
    "model_front.add(layers.MaxPooling2D((2, 2)))\n",
    "model_front.add(Dropout(0.25))\n",
    "model_front.add(layers.Conv2D(32, (3, 3), activation = 'relu'))\n",
    "model_front.add(layers.MaxPooling2D((2, 2)))\n",
    "model_front.add(Dropout(0.25))\n",
    "model_front.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model_front.add(layers.MaxPooling2D((2, 2)))\n",
    "model_front.add(Dropout(0.25))\n",
    "model_front.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model_front.add(layers.MaxPooling2D((2, 2)))\n",
    "model_front.add(Dropout(0.25))\n",
    "\n",
    "model_front.add(layers.Flatten())\n",
    "model_front.add(layers.Dense(128, activation = 'relu'))\n",
    "model_front.add(Dropout(0.5))\n",
    "model_front.add(layers.Dense(250, activation = 'softmax'))\n",
    "\n",
    "\n",
    "# 訓練與識別背面原始影像的模型\n",
    "model_back = models.Sequential()\n",
    "model_back.add(layers.Conv2D(16, (3, 3), activation = 'relu', input_shape = (image_size, image_size, 3)))\n",
    "model_back.add(layers.MaxPooling2D((2, 2)))\n",
    "model_back.add(Dropout(0.25))\n",
    "model_back.add(layers.Conv2D(32, (3, 3), activation = 'relu'))\n",
    "model_back.add(layers.MaxPooling2D((2, 2)))\n",
    "model_back.add(Dropout(0.25))\n",
    "model_back.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model_back.add(layers.MaxPooling2D((2, 2)))\n",
    "model_back.add(Dropout(0.25))\n",
    "model_back.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model_back.add(layers.MaxPooling2D((2, 2)))\n",
    "model_back.add(Dropout(0.25))\n",
    "\n",
    "model_back.add(layers.Flatten())\n",
    "model_back.add(layers.Dense(128, activation = 'relu'))\n",
    "model_back.add(Dropout(0.5))\n",
    "model_back.add(layers.Dense(250, activation = 'softmax'))\n",
    "\n",
    "\n",
    "# 訓練與識別雙面拼整影像的模型\n",
    "model_high = models.Sequential()\n",
    "model_high.add(layers.Conv2D(16, (3, 3), activation = 'relu', input_shape = (image_size, image_size, 3)))\n",
    "model_high.add(layers.MaxPooling2D((2, 2)))\n",
    "model_high.add(Dropout(0.25))\n",
    "model_high.add(layers.Conv2D(32, (3, 3), activation = 'relu'))\n",
    "model_high.add(layers.MaxPooling2D((2, 2)))\n",
    "model_high.add(Dropout(0.25))\n",
    "model_high.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model_high.add(layers.MaxPooling2D((2, 2)))\n",
    "model_high.add(Dropout(0.25))\n",
    "model_high.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model_high.add(layers.MaxPooling2D((2, 2)))\n",
    "model_high.add(Dropout(0.25))\n",
    "\n",
    "model_high.add(layers.Flatten())\n",
    "model_high.add(layers.Dense(128, activation = 'relu'))\n",
    "model_high.add(Dropout(0.5))\n",
    "model_high.add(layers.Dense(250, activation = 'softmax'))\n",
    "\n",
    "\n",
    "# 看看模型長什麼樣子\n",
    "model_high.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. 編譯模型\n",
    "使用 'categorical_crossentropy' 作為損失函數，讓「網路輸出」的機率分佈與「真實標籤」的分佈盡可能一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_front.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model_back.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model_high.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. 採用 Generator 批量生成訓練與驗證資料\n",
    "使用驗證資料集來確認該在何時執行 Early Stopping，以便稍後（Step 8）選用最佳模型進行測試資料集的效果評估。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status of front images:\n",
      "[Training set]\n",
      "Found 9000 images belonging to 250 classes.\n",
      "[Validation set]\n",
      "Found 4500 images belonging to 250 classes.\n",
      "\n",
      "Status of back images:\n",
      "[Training set]\n",
      "Found 9000 images belonging to 250 classes.\n",
      "[Validation set]\n",
      "Found 4500 images belonging to 250 classes.\n",
      "\n",
      "Status of highlighted images:\n",
      "[Training set]\n",
      "Found 9000 images belonging to 250 classes.\n",
      "[Validation set]\n",
      "Found 4500 images belonging to 250 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 從同一個 training 資料路徑下拆分出 training 與 validation 的數據集。\n",
    "# 設定 validation_split=0.35，從每類 54 張訓練樣本中抽取 18 張作為驗證樣本。\n",
    "\n",
    "data_generator = ImageDataGenerator(rescale=1./255, validation_split=0.35)\n",
    "\n",
    "# 正面原始影像的 Generator\n",
    "\n",
    "print(\"Status of front images:\")\n",
    "\n",
    "print(\"[Training set]\")\n",
    "\n",
    "front_train_gen = data_generator.flow_from_directory(\n",
    "        front_train_dir,\n",
    "        target_size = (image_size, image_size),\n",
    "        shuffle = True,\n",
    "        seed = 7,\n",
    "        class_mode = 'categorical', # 多類別，所以使用 categorical 標籤，返回 2D 的 one-hot 編碼標籤。\n",
    "        batch_size = 36,\n",
    "        subset = \"training\") # 因為啟用了 validation_split，故可設定 train_generator 放的是「訓練子集」。\n",
    "\n",
    "print(\"[Validation set]\")\n",
    "\n",
    "front_validation_gen = data_generator.flow_from_directory(\n",
    "        front_train_dir, # 一樣從 training 的路徑下抓取驗證用數據。\n",
    "        target_size = (image_size, image_size),\n",
    "        shuffle = True,\n",
    "        seed = 7,\n",
    "        class_mode = 'categorical',\n",
    "        batch_size = 36,\n",
    "        subset = \"validation\") # 因為啟用了 validation_split，故可設定 validation_generator 放的是「驗證子集」。\n",
    "\n",
    "# 背面原始影像的 Generator\n",
    "\n",
    "print(\"\\nStatus of back images:\")\n",
    "\n",
    "print(\"[Training set]\")\n",
    "\n",
    "back_train_gen = data_generator.flow_from_directory(\n",
    "        back_train_dir,\n",
    "        target_size = (image_size, image_size),\n",
    "        shuffle = True,\n",
    "        seed = 7,\n",
    "        class_mode = 'categorical',\n",
    "        batch_size = 36,\n",
    "        subset = \"training\")\n",
    "\n",
    "print(\"[Validation set]\")\n",
    "\n",
    "back_validation_gen = data_generator.flow_from_directory(\n",
    "        back_train_dir,\n",
    "        target_size = (image_size, image_size),\n",
    "        shuffle = True,\n",
    "        seed = 7,\n",
    "        class_mode = 'categorical',\n",
    "        batch_size = 36,\n",
    "        subset = \"validation\")\n",
    "\n",
    "# 雙面拼整影像的 Generator\n",
    "\n",
    "print(\"\\nStatus of highlighted images:\")\n",
    "\n",
    "print(\"[Training set]\")\n",
    "\n",
    "high_train_gen = data_generator.flow_from_directory(\n",
    "        high_train_dir,\n",
    "        target_size = (image_size, image_size),\n",
    "        shuffle = True,\n",
    "        seed = 7,\n",
    "        class_mode = 'categorical',\n",
    "        batch_size = 36,\n",
    "        subset = \"training\")\n",
    "\n",
    "print(\"[Validation set]\")\n",
    "\n",
    "high_validation_gen = data_generator.flow_from_directory(\n",
    "        high_train_dir,\n",
    "        target_size = (image_size, image_size),\n",
    "        shuffle = True,\n",
    "        seed = 7,\n",
    "        class_mode = 'categorical',\n",
    "        batch_size = 36,\n",
    "        subset = \"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. 定義 Callback Function 以計算 Percision / Recall / F1-Score\n",
    "Keras 提供的...只能在xxx計算一次，不是每個 Epoch。此外，Generator 若要使用 Callback 函式，需有特別的設計方法。\n",
    "\n",
    "### 參考資料\n",
    "* https://medium.com/@thongonary/how-to-compute-f1-score-for-each-epoch-in-keras-a1acd17715a2\n",
    "* https://github.com/keras-team/keras/issues/10472#issuecomment-472543538"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "\n",
    "# 紀錄每個 Epoch 訓練結束時，使用驗證集測試得到的 F1-score 結果\n",
    "front_f1s = []\n",
    "back_f1s = []\n",
    "high_f1s = []\n",
    "\n",
    "class MetricsFront(Callback):\n",
    "\n",
    "    def __init__(self, val_data = front_validation_gen, batch_size = 36):\n",
    "        super().__init__()\n",
    "        self.validation_data = val_data\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        batches = len(self.validation_data)\n",
    "        total = batches * self.batch_size\n",
    "        \n",
    "        val_pred = np.zeros((total, 250))\n",
    "        val_true = np.zeros((total, 250))\n",
    "        \n",
    "        for batch in range(batches):\n",
    "            xVal, yVal = next(self.validation_data)\n",
    "            val_pred[batch * self.batch_size : (batch + 1) * self.batch_size] = np.asarray(self.model.predict(xVal)).round()\n",
    "            val_true[batch * self.batch_size : (batch + 1) * self.batch_size] = yVal\n",
    "            \n",
    "        val_pred = np.squeeze(val_pred)\n",
    "        _val_f1 = f1_score(val_true, val_pred, average = 'micro')\n",
    "        _val_precision = precision_score(val_true, val_pred, average = 'micro')\n",
    "        _val_recall = recall_score(val_true, val_pred, average = 'micro')\n",
    "        \n",
    "        front_f1s.append(_val_f1)\n",
    "\n",
    "        print(\"- val_f1: %f - val_precision: %f - val_recall: %f\"%(_val_f1, _val_precision, _val_recall))\n",
    "        return\n",
    "    \n",
    "class MetricsBack(Callback):\n",
    "\n",
    "    def __init__(self, val_data = back_validation_gen, batch_size = 36):\n",
    "        super().__init__()\n",
    "        self.validation_data = val_data\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        batches = len(self.validation_data)\n",
    "        total = batches * self.batch_size\n",
    "        \n",
    "        val_pred = np.zeros((total, 250))\n",
    "        val_true = np.zeros((total, 250))\n",
    "        \n",
    "        for batch in range(batches):\n",
    "            xVal, yVal = next(self.validation_data)\n",
    "            val_pred[batch * self.batch_size : (batch + 1) * self.batch_size] = np.asarray(self.model.predict(xVal)).round()\n",
    "            val_true[batch * self.batch_size : (batch + 1) * self.batch_size] = yVal\n",
    "            \n",
    "        val_pred = np.squeeze(val_pred)\n",
    "        _val_f1 = f1_score(val_true, val_pred, average = 'micro')\n",
    "        _val_precision = precision_score(val_true, val_pred, average = 'micro')\n",
    "        _val_recall = recall_score(val_true, val_pred, average = 'micro')\n",
    "        \n",
    "        back_f1s.append(_val_f1)\n",
    "        \n",
    "        print(\"- val_f1: %f - val_precision: %f - val_recall: %f\"%(_val_f1, _val_precision, _val_recall))\n",
    "        return\n",
    "    \n",
    "class MetricsHigh(Callback):\n",
    "\n",
    "    def __init__(self, val_data = high_validation_gen, batch_size = 36):\n",
    "        super().__init__()\n",
    "        self.validation_data = val_data\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        batches = len(self.validation_data)\n",
    "        total = batches * self.batch_size\n",
    "        \n",
    "        val_pred = np.zeros((total, 250))\n",
    "        val_true = np.zeros((total, 250))\n",
    "        \n",
    "        for batch in range(batches):\n",
    "            xVal, yVal = next(self.validation_data)\n",
    "            val_pred[batch * self.batch_size : (batch + 1) * self.batch_size] = np.asarray(self.model.predict(xVal)).round()\n",
    "            val_true[batch * self.batch_size : (batch + 1) * self.batch_size] = yVal\n",
    "            \n",
    "        val_pred = np.squeeze(val_pred)\n",
    "        _val_f1 = f1_score(val_true, val_pred, average = 'micro')\n",
    "        _val_precision = precision_score(val_true, val_pred, average = 'micro')\n",
    "        _val_recall = recall_score(val_true, val_pred, average = 'micro')\n",
    "        \n",
    "        high_f1s.append(_val_f1)\n",
    "        \n",
    "        print(\"- val_f1: %f - val_precision: %f - val_recall: %f\"%(_val_f1, _val_precision, _val_recall))\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. 訓練與驗證深度學習網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Front images training:\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 129s 515ms/step - loss: 5.4194 - acc: 0.0050 - val_loss: 5.2748 - val_acc: 0.0142\n",
      "- val_f1: 0.000000 - val_precision: 0.000000 - val_recall: 0.000000\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 122s 490ms/step - loss: 5.0331 - acc: 0.0203 - val_loss: 4.6401 - val_acc: 0.0729\n",
      "- val_f1: 0.000000 - val_precision: 0.000000 - val_recall: 0.000000\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 122s 489ms/step - loss: 4.4642 - acc: 0.0623 - val_loss: 4.1179 - val_acc: 0.1180\n",
      "- val_f1: 0.024492 - val_precision: 0.767123 - val_recall: 0.012444\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 123s 490ms/step - loss: 3.9443 - acc: 0.1114 - val_loss: 3.6585 - val_acc: 0.2127\n",
      "- val_f1: 0.053494 - val_precision: 0.911765 - val_recall: 0.027556\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 123s 490ms/step - loss: 3.5353 - acc: 0.1630 - val_loss: 3.3398 - val_acc: 0.2491\n",
      "- val_f1: 0.092964 - val_precision: 0.944206 - val_recall: 0.048889\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 122s 488ms/step - loss: 3.2430 - acc: 0.2081 - val_loss: 2.7217 - val_acc: 0.3716\n",
      "- val_f1: 0.213891 - val_precision: 0.954225 - val_recall: 0.120444\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 122s 488ms/step - loss: 2.9650 - acc: 0.2512 - val_loss: 2.6130 - val_acc: 0.3478\n",
      "- val_f1: 0.265101 - val_precision: 0.896287 - val_recall: 0.155556\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 122s 486ms/step - loss: 2.7723 - acc: 0.2872 - val_loss: 2.2834 - val_acc: 0.4402\n",
      "- val_f1: 0.360603 - val_precision: 0.935754 - val_recall: 0.223333\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 122s 487ms/step - loss: 2.5775 - acc: 0.3279 - val_loss: 2.1955 - val_acc: 0.4433\n",
      "- val_f1: 0.381267 - val_precision: 0.880225 - val_recall: 0.243333\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 123s 490ms/step - loss: 2.4436 - acc: 0.3528 - val_loss: 1.9905 - val_acc: 0.4933\n",
      "- val_f1: 0.402293 - val_precision: 0.921241 - val_recall: 0.257333\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 122s 486ms/step - loss: 2.3192 - acc: 0.3753 - val_loss: 1.9423 - val_acc: 0.4958\n",
      "- val_f1: 0.444744 - val_precision: 0.923616 - val_recall: 0.292889\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 122s 489ms/step - loss: 2.2097 - acc: 0.4069 - val_loss: 1.9962 - val_acc: 0.4500\n",
      "- val_f1: 0.437345 - val_precision: 0.857236 - val_recall: 0.293556\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 122s 489ms/step - loss: 2.0957 - acc: 0.4241 - val_loss: 1.9497 - val_acc: 0.4633\n",
      "- val_f1: 0.437137 - val_precision: 0.865220 - val_recall: 0.292444\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 122s 488ms/step - loss: 2.0247 - acc: 0.4356 - val_loss: 1.6985 - val_acc: 0.5336\n",
      "- val_f1: 0.490639 - val_precision: 0.896226 - val_recall: 0.337778\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 122s 490ms/step - loss: 1.9315 - acc: 0.4567 - val_loss: 1.5166 - val_acc: 0.5951\n",
      "- val_f1: 0.532811 - val_precision: 0.902387 - val_recall: 0.378000\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 122s 488ms/step - loss: 1.8550 - acc: 0.4748 - val_loss: 1.6813 - val_acc: 0.5302\n",
      "- val_f1: 0.531975 - val_precision: 0.902660 - val_recall: 0.377111\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 122s 489ms/step - loss: 1.7895 - acc: 0.4962 - val_loss: 1.6280 - val_acc: 0.5356\n",
      "- val_f1: 0.507557 - val_precision: 0.870410 - val_recall: 0.358222\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 122s 489ms/step - loss: 1.7310 - acc: 0.5103 - val_loss: 1.7319 - val_acc: 0.5042\n",
      "- val_f1: 0.486512 - val_precision: 0.804615 - val_recall: 0.348667\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 122s 488ms/step - loss: 1.6537 - acc: 0.5328 - val_loss: 1.8308 - val_acc: 0.4827\n",
      "- val_f1: 0.479949 - val_precision: 0.828790 - val_recall: 0.337778\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 121s 486ms/step - loss: 1.6019 - acc: 0.5424 - val_loss: 1.2586 - val_acc: 0.6576\n",
      "- val_f1: 0.601723 - val_precision: 0.906893 - val_recall: 0.450222\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 121s 484ms/step - loss: 1.5626 - acc: 0.5479 - val_loss: 1.7123 - val_acc: 0.5258\n",
      "- val_f1: 0.531481 - val_precision: 0.869697 - val_recall: 0.382667\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 122s 486ms/step - loss: 1.5313 - acc: 0.5600 - val_loss: 1.2658 - val_acc: 0.6436\n",
      "- val_f1: 0.611062 - val_precision: 0.923181 - val_recall: 0.456667\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 122s 487ms/step - loss: 1.4367 - acc: 0.5803 - val_loss: 1.5209 - val_acc: 0.5700\n",
      "- val_f1: 0.571512 - val_precision: 0.832483 - val_recall: 0.435111\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 121s 486ms/step - loss: 1.4384 - acc: 0.5833 - val_loss: 1.3930 - val_acc: 0.6071\n",
      "- val_f1: 0.573260 - val_precision: 0.870530 - val_recall: 0.427333\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 122s 487ms/step - loss: 1.4219 - acc: 0.5844 - val_loss: 1.3031 - val_acc: 0.6173\n",
      "- val_f1: 0.602896 - val_precision: 0.881900 - val_recall: 0.458000\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 122s 487ms/step - loss: 1.3715 - acc: 0.6058 - val_loss: 1.6604 - val_acc: 0.5320\n",
      "- val_f1: 0.547841 - val_precision: 0.797114 - val_recall: 0.417333\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 122s 487ms/step - loss: 1.3457 - acc: 0.6033 - val_loss: 1.4595 - val_acc: 0.5729\n",
      "- val_f1: 0.569308 - val_precision: 0.796008 - val_recall: 0.443111\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 121s 486ms/step - loss: 1.3122 - acc: 0.6104 - val_loss: 1.1392 - val_acc: 0.6616\n",
      "- val_f1: 0.654985 - val_precision: 0.875139 - val_recall: 0.523333\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 122s 487ms/step - loss: 1.2721 - acc: 0.6284 - val_loss: 1.2847 - val_acc: 0.6273\n",
      "- val_f1: 0.618732 - val_precision: 0.879918 - val_recall: 0.477111\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 121s 485ms/step - loss: 1.2820 - acc: 0.6263 - val_loss: 1.3016 - val_acc: 0.6224\n",
      "- val_f1: 0.594059 - val_precision: 0.886634 - val_recall: 0.446667\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 122s 489ms/step - loss: 1.2471 - acc: 0.6391 - val_loss: 1.1906 - val_acc: 0.6544\n",
      "- val_f1: 0.651404 - val_precision: 0.842142 - val_recall: 0.531111\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 122s 488ms/step - loss: 1.2032 - acc: 0.6451 - val_loss: 1.4872 - val_acc: 0.5922\n",
      "- val_f1: 0.592901 - val_precision: 0.788348 - val_recall: 0.475111\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 122s 486ms/step - loss: 1.2047 - acc: 0.6481 - val_loss: 1.1533 - val_acc: 0.6736\n",
      "- val_f1: 0.650994 - val_precision: 0.879063 - val_recall: 0.516889\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 122s 490ms/step - loss: 1.1847 - acc: 0.6540 - val_loss: 1.3527 - val_acc: 0.6229\n",
      "- val_f1: 0.637195 - val_precision: 0.825380 - val_recall: 0.518889\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 123s 491ms/step - loss: 1.1746 - acc: 0.6579 - val_loss: 1.3695 - val_acc: 0.6082\n",
      "- val_f1: 0.606198 - val_precision: 0.841358 - val_recall: 0.473778\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 122s 487ms/step - loss: 1.1602 - acc: 0.6538 - val_loss: 1.5011 - val_acc: 0.5902\n",
      "- val_f1: 0.599892 - val_precision: 0.759360 - val_recall: 0.495778\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 122s 486ms/step - loss: 1.1405 - acc: 0.6656 - val_loss: 1.1764 - val_acc: 0.6653\n",
      "- val_f1: 0.663436 - val_precision: 0.807717 - val_recall: 0.562889\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 121s 486ms/step - loss: 1.1154 - acc: 0.6731 - val_loss: 1.1716 - val_acc: 0.6638\n",
      "- val_f1: 0.675383 - val_precision: 0.832357 - val_recall: 0.568222\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 122s 486ms/step - loss: 1.1472 - acc: 0.6648 - val_loss: 1.2595 - val_acc: 0.6580\n",
      "- val_f1: 0.657441 - val_precision: 0.796835 - val_recall: 0.559556\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 121s 485ms/step - loss: 1.1338 - acc: 0.6704 - val_loss: 1.4170 - val_acc: 0.5982\n",
      "- val_f1: 0.589715 - val_precision: 0.780176 - val_recall: 0.474000\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 122s 487ms/step - loss: 1.1116 - acc: 0.6777 - val_loss: 1.7727 - val_acc: 0.5424\n",
      "- val_f1: 0.561839 - val_precision: 0.692960 - val_recall: 0.472444\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 121s 484ms/step - loss: 1.0874 - acc: 0.6831 - val_loss: 1.1331 - val_acc: 0.6929\n",
      "- val_f1: 0.679606 - val_precision: 0.845797 - val_recall: 0.568000\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 122s 487ms/step - loss: 1.0842 - acc: 0.6782 - val_loss: 1.7691 - val_acc: 0.5342\n",
      "- val_f1: 0.533627 - val_precision: 0.700108 - val_recall: 0.431111\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 121s 486ms/step - loss: 1.0919 - acc: 0.6806 - val_loss: 1.1805 - val_acc: 0.6576\n",
      "- val_f1: 0.654512 - val_precision: 0.807103 - val_recall: 0.550444\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 121s 485ms/step - loss: 1.1051 - acc: 0.6820 - val_loss: 1.0850 - val_acc: 0.6893\n",
      "- val_f1: 0.694814 - val_precision: 0.808975 - val_recall: 0.608889\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 121s 485ms/step - loss: 1.0946 - acc: 0.6848 - val_loss: 1.2973 - val_acc: 0.6344\n",
      "- val_f1: 0.629610 - val_precision: 0.807371 - val_recall: 0.516000\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 122s 487ms/step - loss: 1.0719 - acc: 0.6889 - val_loss: 1.6800 - val_acc: 0.5471\n",
      "- val_f1: 0.554243 - val_precision: 0.700136 - val_recall: 0.458667\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 122s 486ms/step - loss: 1.0953 - acc: 0.6876 - val_loss: 1.4245 - val_acc: 0.6238\n",
      "- val_f1: 0.620421 - val_precision: 0.746717 - val_recall: 0.530667\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 122s 487ms/step - loss: 1.0884 - acc: 0.6883 - val_loss: 1.2632 - val_acc: 0.6449\n",
      "- val_f1: 0.653172 - val_precision: 0.784846 - val_recall: 0.559333\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 122s 487ms/step - loss: 1.0807 - acc: 0.6913 - val_loss: 1.2912 - val_acc: 0.6424\n",
      "- val_f1: 0.649758 - val_precision: 0.789139 - val_recall: 0.552222\n",
      "\n",
      "Back images training:\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 133s 533ms/step - loss: 5.4900 - acc: 0.0053 - val_loss: 5.3742 - val_acc: 0.0071\n",
      "- val_f1: 0.007504 - val_precision: 0.548387 - val_recall: 0.003778\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 129s 516ms/step - loss: 5.2301 - acc: 0.0128 - val_loss: 5.0156 - val_acc: 0.0211\n",
      "- val_f1: 0.012767 - val_precision: 0.674419 - val_recall: 0.006444\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 129s 517ms/step - loss: 4.8384 - acc: 0.0348 - val_loss: 4.4560 - val_acc: 0.0769\n",
      "- val_f1: 0.011474 - val_precision: 0.812500 - val_recall: 0.005778\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 130s 518ms/step - loss: 4.3661 - acc: 0.0669 - val_loss: 3.9674 - val_acc: 0.1227\n",
      "- val_f1: 0.025809 - val_precision: 0.819444 - val_recall: 0.013111\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 129s 516ms/step - loss: 3.9669 - acc: 0.1077 - val_loss: 3.6514 - val_acc: 0.1887\n",
      "- val_f1: 0.037424 - val_precision: 0.895833 - val_recall: 0.019111\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 129s 516ms/step - loss: 3.6129 - acc: 0.1489 - val_loss: 3.1096 - val_acc: 0.2953\n",
      "- val_f1: 0.057094 - val_precision: 0.836478 - val_recall: 0.029556\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 129s 517ms/step - loss: 3.3150 - acc: 0.1904 - val_loss: 3.2649 - val_acc: 0.2284\n",
      "- val_f1: 0.074782 - val_precision: 0.850242 - val_recall: 0.039111\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 129s 517ms/step - loss: 3.0386 - acc: 0.2293 - val_loss: 2.8670 - val_acc: 0.2958\n",
      "- val_f1: 0.085822 - val_precision: 0.803150 - val_recall: 0.045333\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 129s 516ms/step - loss: 2.8224 - acc: 0.2719 - val_loss: 2.4045 - val_acc: 0.4338\n",
      "- val_f1: 0.129725 - val_precision: 0.920821 - val_recall: 0.069778\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 129s 516ms/step - loss: 2.6342 - acc: 0.3034 - val_loss: 2.0272 - val_acc: 0.5220\n",
      "- val_f1: 0.206639 - val_precision: 0.890017 - val_recall: 0.116889\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 129s 517ms/step - loss: 2.4584 - acc: 0.3447 - val_loss: 2.0712 - val_acc: 0.4647\n",
      "- val_f1: 0.229691 - val_precision: 0.845827 - val_recall: 0.132889\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 129s 517ms/step - loss: 2.2956 - acc: 0.3720 - val_loss: 1.7897 - val_acc: 0.5431\n",
      "- val_f1: 0.309480 - val_precision: 0.909978 - val_recall: 0.186444\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 129s 516ms/step - loss: 2.1604 - acc: 0.4093 - val_loss: 1.5459 - val_acc: 0.6247\n",
      "- val_f1: 0.411450 - val_precision: 0.918399 - val_recall: 0.265111\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 129s 516ms/step - loss: 2.0334 - acc: 0.4416 - val_loss: 1.5675 - val_acc: 0.5918\n",
      "- val_f1: 0.417530 - val_precision: 0.886085 - val_recall: 0.273111\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 129s 515ms/step - loss: 1.9136 - acc: 0.4567 - val_loss: 1.6663 - val_acc: 0.5627\n",
      "- val_f1: 0.385953 - val_precision: 0.886581 - val_recall: 0.246667\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 129s 516ms/step - loss: 1.8170 - acc: 0.4810 - val_loss: 1.6063 - val_acc: 0.5618\n",
      "- val_f1: 0.446798 - val_precision: 0.837508 - val_recall: 0.304667\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 130s 519ms/step - loss: 1.7201 - acc: 0.5103 - val_loss: 1.4210 - val_acc: 0.6142\n",
      "- val_f1: 0.498809 - val_precision: 0.873263 - val_recall: 0.349111\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 129s 516ms/step - loss: 1.6475 - acc: 0.5227 - val_loss: 1.6691 - val_acc: 0.5311\n",
      "- val_f1: 0.442652 - val_precision: 0.807534 - val_recall: 0.304889\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 129s 517ms/step - loss: 1.5535 - acc: 0.5489 - val_loss: 1.3070 - val_acc: 0.6302\n",
      "- val_f1: 0.558397 - val_precision: 0.853681 - val_recall: 0.414889\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 129s 517ms/step - loss: 1.5283 - acc: 0.5561 - val_loss: 1.1851 - val_acc: 0.6673\n",
      "- val_f1: 0.619075 - val_precision: 0.885124 - val_recall: 0.476000\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 131s 522ms/step - loss: 1.4266 - acc: 0.5794 - val_loss: 1.1654 - val_acc: 0.6789\n",
      "- val_f1: 0.621995 - val_precision: 0.864373 - val_recall: 0.485778\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 129s 516ms/step - loss: 1.3796 - acc: 0.5959 - val_loss: 1.6039 - val_acc: 0.5576\n",
      "- val_f1: 0.523865 - val_precision: 0.750207 - val_recall: 0.402444\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 129s 518ms/step - loss: 1.3478 - acc: 0.6034 - val_loss: 1.4980 - val_acc: 0.5796\n",
      "- val_f1: 0.528218 - val_precision: 0.792092 - val_recall: 0.396222\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 129s 517ms/step - loss: 1.2895 - acc: 0.6170 - val_loss: 1.1265 - val_acc: 0.6842\n",
      "- val_f1: 0.655889 - val_precision: 0.843761 - val_recall: 0.536444\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 129s 517ms/step - loss: 1.2439 - acc: 0.6268 - val_loss: 0.9723 - val_acc: 0.7242\n",
      "- val_f1: 0.700481 - val_precision: 0.877005 - val_recall: 0.583111\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 129s 516ms/step - loss: 1.1938 - acc: 0.6456 - val_loss: 0.8767 - val_acc: 0.7518\n",
      "- val_f1: 0.722134 - val_precision: 0.889974 - val_recall: 0.607556\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 129s 514ms/step - loss: 1.1936 - acc: 0.6407 - val_loss: 1.1306 - val_acc: 0.6784\n",
      "- val_f1: 0.653376 - val_precision: 0.812831 - val_recall: 0.546222\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 130s 520ms/step - loss: 1.1264 - acc: 0.6668 - val_loss: 0.8348 - val_acc: 0.7556\n",
      "- val_f1: 0.735188 - val_precision: 0.874387 - val_recall: 0.634222\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 129s 515ms/step - loss: 1.0990 - acc: 0.6761 - val_loss: 1.0210 - val_acc: 0.7093\n",
      "- val_f1: 0.704566 - val_precision: 0.836336 - val_recall: 0.608667\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 128s 514ms/step - loss: 1.0626 - acc: 0.6739 - val_loss: 1.0462 - val_acc: 0.6927\n",
      "- val_f1: 0.678512 - val_precision: 0.806550 - val_recall: 0.585556\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 129s 516ms/step - loss: 1.0479 - acc: 0.6789 - val_loss: 0.9196 - val_acc: 0.7444\n",
      "- val_f1: 0.715553 - val_precision: 0.884779 - val_recall: 0.600667\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 129s 516ms/step - loss: 1.0034 - acc: 0.6950 - val_loss: 1.3134 - val_acc: 0.6344\n",
      "- val_f1: 0.637789 - val_precision: 0.756402 - val_recall: 0.551333\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 129s 514ms/step - loss: 0.9939 - acc: 0.7018 - val_loss: 0.9551 - val_acc: 0.7222\n",
      "- val_f1: 0.712788 - val_precision: 0.839458 - val_recall: 0.619333\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 129s 516ms/step - loss: 0.9744 - acc: 0.7056 - val_loss: 0.8886 - val_acc: 0.7398\n",
      "- val_f1: 0.732483 - val_precision: 0.847998 - val_recall: 0.644667\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 129s 515ms/step - loss: 0.9829 - acc: 0.7037 - val_loss: 0.9453 - val_acc: 0.7282\n",
      "- val_f1: 0.724025 - val_precision: 0.834203 - val_recall: 0.639556\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 129s 516ms/step - loss: 0.9588 - acc: 0.7161 - val_loss: 0.8988 - val_acc: 0.7484\n",
      "- val_f1: 0.740899 - val_precision: 0.855190 - val_recall: 0.653556\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 129s 516ms/step - loss: 0.9253 - acc: 0.7240 - val_loss: 0.8216 - val_acc: 0.7669\n",
      "- val_f1: 0.756300 - val_precision: 0.856821 - val_recall: 0.676889\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 129s 516ms/step - loss: 0.9276 - acc: 0.7189 - val_loss: 0.9768 - val_acc: 0.7224\n",
      "- val_f1: 0.717846 - val_precision: 0.817253 - val_recall: 0.640000\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 129s 517ms/step - loss: 0.9055 - acc: 0.7302 - val_loss: 0.8692 - val_acc: 0.7444\n",
      "- val_f1: 0.740138 - val_precision: 0.831118 - val_recall: 0.667111\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 129s 515ms/step - loss: 0.8732 - acc: 0.7388 - val_loss: 0.8121 - val_acc: 0.7607\n",
      "- val_f1: 0.753218 - val_precision: 0.850000 - val_recall: 0.676222\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 129s 516ms/step - loss: 0.8973 - acc: 0.7318 - val_loss: 1.0332 - val_acc: 0.7109\n",
      "- val_f1: 0.691964 - val_precision: 0.845635 - val_recall: 0.585556\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 128s 514ms/step - loss: 0.8932 - acc: 0.7309 - val_loss: 1.0225 - val_acc: 0.7020\n",
      "- val_f1: 0.701361 - val_precision: 0.820482 - val_recall: 0.612444\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 129s 516ms/step - loss: 0.8755 - acc: 0.7437 - val_loss: 1.0292 - val_acc: 0.7009\n",
      "- val_f1: 0.696696 - val_precision: 0.830973 - val_recall: 0.599778\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 129s 514ms/step - loss: 0.8614 - acc: 0.7388 - val_loss: 1.2979 - val_acc: 0.6476\n",
      "- val_f1: 0.629877 - val_precision: 0.789879 - val_recall: 0.523778\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 129s 514ms/step - loss: 0.8787 - acc: 0.7390 - val_loss: 0.8443 - val_acc: 0.7584\n",
      "- val_f1: 0.757038 - val_precision: 0.856582 - val_recall: 0.678222\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 128s 514ms/step - loss: 0.8555 - acc: 0.7456 - val_loss: 0.9437 - val_acc: 0.7353\n",
      "- val_f1: 0.739416 - val_precision: 0.816935 - val_recall: 0.675333\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 129s 515ms/step - loss: 0.8592 - acc: 0.7400 - val_loss: 0.9019 - val_acc: 0.7442\n",
      "- val_f1: 0.749114 - val_precision: 0.832202 - val_recall: 0.681111\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 129s 515ms/step - loss: 0.8371 - acc: 0.7558 - val_loss: 0.9172 - val_acc: 0.7376\n",
      "- val_f1: 0.738643 - val_precision: 0.806791 - val_recall: 0.681111\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 129s 515ms/step - loss: 0.8591 - acc: 0.7526 - val_loss: 0.9931 - val_acc: 0.7227\n",
      "- val_f1: 0.712859 - val_precision: 0.841294 - val_recall: 0.618444\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 129s 515ms/step - loss: 0.8473 - acc: 0.7574 - val_loss: 0.7045 - val_acc: 0.8013\n",
      "- val_f1: 0.792397 - val_precision: 0.883995 - val_recall: 0.718000\n",
      "\n",
      "Highlighted images training:\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 102s 408ms/step - loss: 5.4868 - acc: 0.0070 - val_loss: 5.3170 - val_acc: 0.0249\n",
      "- val_f1: 0.000000 - val_precision: 0.000000 - val_recall: 0.000000\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 4.7933 - acc: 0.0482 - val_loss: 4.0546 - val_acc: 0.1451\n",
      "- val_f1: 0.054416 - val_precision: 0.961832 - val_recall: 0.028000\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 3.8414 - acc: 0.1440 - val_loss: 3.0862 - val_acc: 0.3347\n",
      "- val_f1: 0.163191 - val_precision: 0.917995 - val_recall: 0.089556\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 3.0546 - acc: 0.2680 - val_loss: 1.9728 - val_acc: 0.6089\n",
      "- val_f1: 0.417598 - val_precision: 0.973941 - val_recall: 0.265778\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 2.4190 - acc: 0.3830 - val_loss: 1.5178 - val_acc: 0.6849\n",
      "- val_f1: 0.549570 - val_precision: 0.971815 - val_recall: 0.383111\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 1.9598 - acc: 0.4838 - val_loss: 1.2327 - val_acc: 0.7196\n",
      "- val_f1: 0.640569 - val_precision: 0.962567 - val_recall: 0.480000\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 1.6151 - acc: 0.5560 - val_loss: 0.7860 - val_acc: 0.8480\n",
      "- val_f1: 0.755355 - val_precision: 0.978438 - val_recall: 0.615111\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 99s 394ms/step - loss: 1.3605 - acc: 0.6191 - val_loss: 0.6392 - val_acc: 0.8473\n",
      "- val_f1: 0.813481 - val_precision: 0.955896 - val_recall: 0.708000\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 99s 395ms/step - loss: 1.1155 - acc: 0.6881 - val_loss: 0.5444 - val_acc: 0.8631\n",
      "- val_f1: 0.834523 - val_precision: 0.956359 - val_recall: 0.740222\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 99s 395ms/step - loss: 0.9954 - acc: 0.7087 - val_loss: 0.4200 - val_acc: 0.9000\n",
      "- val_f1: 0.881700 - val_precision: 0.965116 - val_recall: 0.811556\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 99s 395ms/step - loss: 0.8493 - acc: 0.7539 - val_loss: 0.3908 - val_acc: 0.8938\n",
      "- val_f1: 0.898698 - val_precision: 0.961266 - val_recall: 0.843778\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 99s 395ms/step - loss: 0.7574 - acc: 0.7789 - val_loss: 0.2610 - val_acc: 0.9387\n",
      "- val_f1: 0.933087 - val_precision: 0.972068 - val_recall: 0.897111\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 99s 395ms/step - loss: 0.6799 - acc: 0.7983 - val_loss: 0.2379 - val_acc: 0.9478\n",
      "- val_f1: 0.938314 - val_precision: 0.975078 - val_recall: 0.904222\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 0.6278 - acc: 0.8148 - val_loss: 0.2168 - val_acc: 0.9433\n",
      "- val_f1: 0.937292 - val_precision: 0.968032 - val_recall: 0.908444\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 0.5608 - acc: 0.8311 - val_loss: 0.1625 - val_acc: 0.9571\n",
      "- val_f1: 0.954489 - val_precision: 0.970379 - val_recall: 0.939111\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 0.5228 - acc: 0.8391 - val_loss: 0.1417 - val_acc: 0.9644\n",
      "- val_f1: 0.961010 - val_precision: 0.974851 - val_recall: 0.947556\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 99s 395ms/step - loss: 0.4837 - acc: 0.8560 - val_loss: 0.1782 - val_acc: 0.9489\n",
      "- val_f1: 0.948761 - val_precision: 0.966137 - val_recall: 0.932000\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 99s 395ms/step - loss: 0.4680 - acc: 0.8632 - val_loss: 0.2770 - val_acc: 0.9222\n",
      "- val_f1: 0.923497 - val_precision: 0.946779 - val_recall: 0.901333\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 0.4250 - acc: 0.8709 - val_loss: 0.1878 - val_acc: 0.9467\n",
      "- val_f1: 0.947499 - val_precision: 0.960923 - val_recall: 0.934444\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 99s 395ms/step - loss: 0.3997 - acc: 0.8788 - val_loss: 0.1786 - val_acc: 0.9464\n",
      "- val_f1: 0.947001 - val_precision: 0.959198 - val_recall: 0.935111\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 99s 394ms/step - loss: 0.3815 - acc: 0.8883 - val_loss: 0.0780 - val_acc: 0.9802\n",
      "- val_f1: 0.978576 - val_precision: 0.982743 - val_recall: 0.974444\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 99s 395ms/step - loss: 0.3526 - acc: 0.8919 - val_loss: 0.1131 - val_acc: 0.9684\n",
      "- val_f1: 0.969880 - val_precision: 0.977432 - val_recall: 0.962444\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 99s 395ms/step - loss: 0.3425 - acc: 0.8949 - val_loss: 0.0919 - val_acc: 0.9744\n",
      "- val_f1: 0.975196 - val_precision: 0.980674 - val_recall: 0.969778\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 98s 393ms/step - loss: 0.3413 - acc: 0.8997 - val_loss: 0.1224 - val_acc: 0.9684\n",
      "- val_f1: 0.966267 - val_precision: 0.974678 - val_recall: 0.958000\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 99s 395ms/step - loss: 0.3049 - acc: 0.9071 - val_loss: 0.1664 - val_acc: 0.9567\n",
      "- val_f1: 0.957416 - val_precision: 0.963121 - val_recall: 0.951778\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 0.3020 - acc: 0.9118 - val_loss: 0.1478 - val_acc: 0.9629\n",
      "- val_f1: 0.964346 - val_precision: 0.970092 - val_recall: 0.958667\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 0.2968 - acc: 0.9113 - val_loss: 0.0611 - val_acc: 0.9816\n",
      "- val_f1: 0.981039 - val_precision: 0.984774 - val_recall: 0.977333\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 0.2780 - acc: 0.9159 - val_loss: 0.1391 - val_acc: 0.9611\n",
      "- val_f1: 0.961053 - val_precision: 0.965254 - val_recall: 0.956889\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 0.2911 - acc: 0.9121 - val_loss: 0.1661 - val_acc: 0.9638\n",
      "- val_f1: 0.967648 - val_precision: 0.971550 - val_recall: 0.963778\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 99s 397ms/step - loss: 0.2632 - acc: 0.9212 - val_loss: 0.0860 - val_acc: 0.9776\n",
      "- val_f1: 0.979601 - val_precision: 0.982778 - val_recall: 0.976444\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 0.2678 - acc: 0.9204 - val_loss: 0.0816 - val_acc: 0.9764\n",
      "- val_f1: 0.978031 - val_precision: 0.981643 - val_recall: 0.974444\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 100s 402ms/step - loss: 0.2551 - acc: 0.9270 - val_loss: 0.0835 - val_acc: 0.9767\n",
      "- val_f1: 0.977154 - val_precision: 0.980103 - val_recall: 0.974222\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 101s 403ms/step - loss: 0.2581 - acc: 0.9252 - val_loss: 0.0576 - val_acc: 0.9847\n",
      "- val_f1: 0.984530 - val_precision: 0.986176 - val_recall: 0.982889\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 99s 398ms/step - loss: 0.2656 - acc: 0.9233 - val_loss: 0.1198 - val_acc: 0.9702\n",
      "- val_f1: 0.970595 - val_precision: 0.972979 - val_recall: 0.968222\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 0.2502 - acc: 0.9243 - val_loss: 0.0991 - val_acc: 0.9691\n",
      "- val_f1: 0.970906 - val_precision: 0.974055 - val_recall: 0.967778\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 98s 393ms/step - loss: 0.2317 - acc: 0.9327 - val_loss: 0.1348 - val_acc: 0.9673\n",
      "- val_f1: 0.966786 - val_precision: 0.969812 - val_recall: 0.963778\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 0.2364 - acc: 0.9299 - val_loss: 0.0840 - val_acc: 0.9760\n",
      "- val_f1: 0.975718 - val_precision: 0.978115 - val_recall: 0.973333\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 0.2205 - acc: 0.9353 - val_loss: 0.0537 - val_acc: 0.9833\n",
      "- val_f1: 0.983519 - val_precision: 0.985714 - val_recall: 0.981333\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 99s 394ms/step - loss: 0.2261 - acc: 0.9359 - val_loss: 0.1329 - val_acc: 0.9678\n",
      "- val_f1: 0.969171 - val_precision: 0.970792 - val_recall: 0.967556\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 0.2371 - acc: 0.9343 - val_loss: 0.3708 - val_acc: 0.9182\n",
      "- val_f1: 0.920706 - val_precision: 0.925460 - val_recall: 0.916000\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 0.2223 - acc: 0.9368 - val_loss: 0.1920 - val_acc: 0.9496\n",
      "- val_f1: 0.947791 - val_precision: 0.951613 - val_recall: 0.944000\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 0.2263 - acc: 0.9359 - val_loss: 0.0993 - val_acc: 0.9738\n",
      "- val_f1: 0.975822 - val_precision: 0.978547 - val_recall: 0.973111\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 0.2255 - acc: 0.9330 - val_loss: 0.2390 - val_acc: 0.9449\n",
      "- val_f1: 0.946064 - val_precision: 0.950842 - val_recall: 0.941333\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 0.2062 - acc: 0.9383 - val_loss: 0.0766 - val_acc: 0.9811\n",
      "- val_f1: 0.979651 - val_precision: 0.980414 - val_recall: 0.978889\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 0.2229 - acc: 0.9360 - val_loss: 0.1145 - val_acc: 0.9698\n",
      "- val_f1: 0.966447 - val_precision: 0.969582 - val_recall: 0.963333\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 0.1999 - acc: 0.9452 - val_loss: 0.2577 - val_acc: 0.9422\n",
      "- val_f1: 0.942055 - val_precision: 0.944792 - val_recall: 0.939333\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 0.2082 - acc: 0.9411 - val_loss: 0.1084 - val_acc: 0.9736\n",
      "- val_f1: 0.975078 - val_precision: 0.976381 - val_recall: 0.973778\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 0.2213 - acc: 0.9370 - val_loss: 0.1398 - val_acc: 0.9660\n",
      "- val_f1: 0.965602 - val_precision: 0.967433 - val_recall: 0.963778\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 0.2080 - acc: 0.9426 - val_loss: 0.1182 - val_acc: 0.9662\n",
      "- val_f1: 0.967828 - val_precision: 0.969663 - val_recall: 0.966000\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 99s 397ms/step - loss: 0.2165 - acc: 0.9439 - val_loss: 0.1356 - val_acc: 0.9609\n",
      "- val_f1: 0.963517 - val_precision: 0.967511 - val_recall: 0.959556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faa64d95b00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Front images training:\")\n",
    "\n",
    "model_front.fit_generator(\n",
    "    front_train_gen,\n",
    "    steps_per_epoch = 250,\n",
    "    epochs = 50,\n",
    "    validation_data = front_validation_gen,\n",
    "    validation_steps = 125,\n",
    "    callbacks = [MetricsFront()])\n",
    "\n",
    "print(\"\\nBack images training:\")\n",
    "\n",
    "model_back.fit_generator(\n",
    "    back_train_gen,\n",
    "    steps_per_epoch = 250,\n",
    "    epochs = 50,\n",
    "    validation_data = back_validation_gen,\n",
    "    validation_steps = 125,\n",
    "    callbacks = [MetricsBack()])\n",
    "\n",
    "print(\"\\nHighlighted images training:\")\n",
    "\n",
    "model_high.fit_generator(\n",
    "    high_train_gen,\n",
    "    steps_per_epoch = 250,\n",
    "    epochs = 50,\n",
    "    validation_data = high_validation_gen,\n",
    "    validation_steps = 125,\n",
    "    callbacks = [MetricsHigh()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. 尋找最佳模型並繪製 F1 Score 趨勢圖 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Front]\t\t45 epochs reach the best f1-score value 69.48%\n",
      "[Back]\t\t50 epochs reach the best f1-score value 79.24%\n",
      "[Highlighted]\t33 epochs reach the best f1-score value 98.45%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_front_epochs = front_f1s.index(max(front_f1s)) + 1\n",
    "best_back_epochs = back_f1s.index(max(back_f1s)) + 1\n",
    "best_high_epochs = high_f1s.index(max(high_f1s)) + 1\n",
    "\n",
    "print(\"[Front]\\t\\t%d epochs reach the best f1-score value %.2f%%\"%(best_front_epochs, max(front_f1s) * 100))\n",
    "print(\"[Back]\\t\\t%d epochs reach the best f1-score value %.2f%%\"%(best_back_epochs, max(back_f1s) * 100))\n",
    "print(\"[Highlighted]\\t%d epochs reach the best f1-score value %.2f%%\"%(best_high_epochs, max(high_f1s) * 100))\n",
    "\n",
    "plt.plot(range(50), front_f1s, 'b-o', label = 'Front images')\n",
    "plt.plot(range(50), back_f1s, 'g-o', label = 'Back images')\n",
    "plt.plot(range(50), high_f1s, 'r-o', label = 'Highlighted images')\n",
    "plt.legend()\n",
    "plt.title('Validation F1-score')\n",
    "plt.xlabel('Epochs')\n",
    "plt.xticks(np.arange(0, 50, step = 5), range(1, 51, 5))\n",
    "plt.ylabel('F1-score')\n",
    "plt.figure()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8. 使用完整資料重新訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status of front images:\n",
      "[Training set]\n",
      "Found 13500 images belonging to 250 classes.\n",
      "[Testing set]\n",
      "Found 4500 images belonging to 250 classes.\n",
      "\n",
      "Status of back images:\n",
      "[Training set]\n",
      "Found 13500 images belonging to 250 classes.\n",
      "[Testing set]\n",
      "Found 4500 images belonging to 250 classes.\n",
      "\n",
      "Status of highlighted images:\n",
      "[Training set]\n",
      "Found 13500 images belonging to 250 classes.\n",
      "[Testing set]\n",
      "Found 4500 images belonging to 250 classes.\n",
      "\n",
      "Front images training:\n",
      "Epoch 1/45\n",
      "375/375 [==============================] - 134s 357ms/step - loss: 5.3790 - acc: 0.0074\n",
      "Epoch 2/45\n",
      "375/375 [==============================] - 134s 358ms/step - loss: 4.8721 - acc: 0.0313\n",
      "Epoch 3/45\n",
      "375/375 [==============================] - 134s 357ms/step - loss: 4.2727 - acc: 0.0745\n",
      "Epoch 4/45\n",
      "375/375 [==============================] - 134s 356ms/step - loss: 3.6617 - acc: 0.1407\n",
      "Epoch 5/45\n",
      "375/375 [==============================] - 134s 357ms/step - loss: 3.2400 - acc: 0.2021\n",
      "Epoch 6/45\n",
      "375/375 [==============================] - 134s 357ms/step - loss: 2.8883 - acc: 0.2601\n",
      "Epoch 7/45\n",
      "375/375 [==============================] - 134s 357ms/step - loss: 2.6088 - acc: 0.3166\n",
      "Epoch 8/45\n",
      "375/375 [==============================] - 134s 356ms/step - loss: 2.3966 - acc: 0.3587\n",
      "Epoch 9/45\n",
      "375/375 [==============================] - 134s 357ms/step - loss: 2.1991 - acc: 0.3941\n",
      "Epoch 10/45\n",
      "375/375 [==============================] - 134s 357ms/step - loss: 2.0484 - acc: 0.4309\n",
      "Epoch 11/45\n",
      "375/375 [==============================] - 134s 356ms/step - loss: 1.9423 - acc: 0.4580\n",
      "Epoch 12/45\n",
      "375/375 [==============================] - 134s 356ms/step - loss: 1.8159 - acc: 0.4885\n",
      "Epoch 13/45\n",
      "375/375 [==============================] - 134s 357ms/step - loss: 1.7239 - acc: 0.5087\n",
      "Epoch 14/45\n",
      "375/375 [==============================] - 134s 357ms/step - loss: 1.6488 - acc: 0.5258\n",
      "Epoch 15/45\n",
      "375/375 [==============================] - 134s 356ms/step - loss: 1.5746 - acc: 0.5489\n",
      "Epoch 16/45\n",
      "375/375 [==============================] - 134s 356ms/step - loss: 1.5048 - acc: 0.5589\n",
      "Epoch 17/45\n",
      "375/375 [==============================] - 134s 356ms/step - loss: 1.4470 - acc: 0.5795\n",
      "Epoch 18/45\n",
      "375/375 [==============================] - 133s 356ms/step - loss: 1.4213 - acc: 0.5848\n",
      "Epoch 19/45\n",
      "375/375 [==============================] - 134s 356ms/step - loss: 1.3781 - acc: 0.5956\n",
      "Epoch 20/45\n",
      "375/375 [==============================] - 134s 356ms/step - loss: 1.3483 - acc: 0.6061\n",
      "Epoch 21/45\n",
      "375/375 [==============================] - 134s 357ms/step - loss: 1.3326 - acc: 0.6133\n",
      "Epoch 22/45\n",
      "375/375 [==============================] - 134s 356ms/step - loss: 1.2864 - acc: 0.6245\n",
      "Epoch 23/45\n",
      "375/375 [==============================] - 134s 356ms/step - loss: 1.2938 - acc: 0.6223\n",
      "Epoch 24/45\n",
      "375/375 [==============================] - 134s 356ms/step - loss: 1.2644 - acc: 0.6267\n",
      "Epoch 25/45\n",
      "375/375 [==============================] - 134s 356ms/step - loss: 1.2400 - acc: 0.6389\n",
      "Epoch 26/45\n",
      "375/375 [==============================] - 133s 356ms/step - loss: 1.2235 - acc: 0.6403\n",
      "Epoch 27/45\n",
      "375/375 [==============================] - 133s 356ms/step - loss: 1.2247 - acc: 0.6468\n",
      "Epoch 28/45\n",
      "375/375 [==============================] - 133s 356ms/step - loss: 1.2177 - acc: 0.6517\n",
      "Epoch 29/45\n",
      "375/375 [==============================] - 134s 357ms/step - loss: 1.2434 - acc: 0.6481\n",
      "Epoch 30/45\n",
      "375/375 [==============================] - 134s 356ms/step - loss: 1.2180 - acc: 0.6496\n",
      "Epoch 31/45\n",
      "375/375 [==============================] - 134s 358ms/step - loss: 1.2016 - acc: 0.6590\n",
      "Epoch 32/45\n",
      "375/375 [==============================] - 135s 359ms/step - loss: 1.2349 - acc: 0.6533\n",
      "Epoch 33/45\n",
      "375/375 [==============================] - 135s 361ms/step - loss: 1.1948 - acc: 0.6586\n",
      "Epoch 34/45\n",
      "375/375 [==============================] - 136s 362ms/step - loss: 1.2176 - acc: 0.6579\n",
      "Epoch 35/45\n",
      "375/375 [==============================] - 134s 358ms/step - loss: 1.1972 - acc: 0.6632\n",
      "Epoch 36/45\n",
      "375/375 [==============================] - 134s 358ms/step - loss: 1.2208 - acc: 0.6593\n",
      "Epoch 37/45\n",
      "375/375 [==============================] - 134s 358ms/step - loss: 1.2110 - acc: 0.6627\n",
      "Epoch 38/45\n",
      "375/375 [==============================] - 134s 358ms/step - loss: 1.2015 - acc: 0.6662\n",
      "Epoch 39/45\n",
      "375/375 [==============================] - 135s 359ms/step - loss: 1.2506 - acc: 0.6544\n",
      "Epoch 40/45\n",
      "375/375 [==============================] - 135s 359ms/step - loss: 1.2458 - acc: 0.6590\n",
      "Epoch 41/45\n",
      "375/375 [==============================] - 134s 358ms/step - loss: 1.2472 - acc: 0.6603\n",
      "Epoch 42/45\n",
      "375/375 [==============================] - 134s 357ms/step - loss: 1.2272 - acc: 0.6714\n",
      "Epoch 43/45\n",
      "375/375 [==============================] - 133s 356ms/step - loss: 1.2205 - acc: 0.6638\n",
      "Epoch 44/45\n",
      "375/375 [==============================] - 134s 357ms/step - loss: 1.2478 - acc: 0.6594\n",
      "Epoch 45/45\n",
      "375/375 [==============================] - 134s 356ms/step - loss: 1.2338 - acc: 0.6641\n",
      "\n",
      "Back images training:\n",
      "Epoch 1/50\n",
      "375/375 [==============================] - 142s 378ms/step - loss: 5.5124 - acc: 0.0053\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 141s 376ms/step - loss: 5.0494 - acc: 0.0189\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 141s 377ms/step - loss: 4.4074 - acc: 0.0556\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 141s 377ms/step - loss: 3.8291 - acc: 0.1133\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 141s 377ms/step - loss: 3.3605 - acc: 0.1706\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 141s 377ms/step - loss: 2.9679 - acc: 0.2307\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 141s 376ms/step - loss: 2.6830 - acc: 0.2901\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 141s 376ms/step - loss: 2.4241 - acc: 0.3467\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 141s 376ms/step - loss: 2.2414 - acc: 0.3855\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 141s 376ms/step - loss: 2.0733 - acc: 0.4201\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 141s 376ms/step - loss: 1.9235 - acc: 0.4561\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 141s 376ms/step - loss: 1.8154 - acc: 0.4870\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 141s 376ms/step - loss: 1.7018 - acc: 0.5067\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 141s 377ms/step - loss: 1.6115 - acc: 0.5344\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 141s 377ms/step - loss: 1.5109 - acc: 0.5596\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 141s 376ms/step - loss: 1.4727 - acc: 0.5750\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 141s 376ms/step - loss: 1.4256 - acc: 0.5870\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 141s 376ms/step - loss: 1.3538 - acc: 0.6080\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 141s 376ms/step - loss: 1.3143 - acc: 0.6112\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 142s 378ms/step - loss: 1.2620 - acc: 0.6310\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 142s 379ms/step - loss: 1.2279 - acc: 0.6422\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 142s 379ms/step - loss: 1.2130 - acc: 0.6480\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 141s 377ms/step - loss: 1.1751 - acc: 0.6585\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 141s 375ms/step - loss: 1.1465 - acc: 0.6624\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 140s 374ms/step - loss: 1.1301 - acc: 0.6771\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 140s 375ms/step - loss: 1.1048 - acc: 0.6805\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 140s 374ms/step - loss: 1.0993 - acc: 0.6847\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 141s 375ms/step - loss: 1.0936 - acc: 0.6890\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 141s 375ms/step - loss: 1.0783 - acc: 0.6966\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 141s 376ms/step - loss: 1.0760 - acc: 0.6931\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 141s 375ms/step - loss: 1.0729 - acc: 0.7001\n",
      "Epoch 32/50\n",
      "375/375 [==============================] - 141s 375ms/step - loss: 1.0741 - acc: 0.7009\n",
      "Epoch 33/50\n",
      "375/375 [==============================] - 141s 375ms/step - loss: 1.0443 - acc: 0.7059\n",
      "Epoch 34/50\n",
      "375/375 [==============================] - 141s 375ms/step - loss: 1.0488 - acc: 0.7063\n",
      "Epoch 35/50\n",
      "375/375 [==============================] - 140s 375ms/step - loss: 1.0640 - acc: 0.7076\n",
      "Epoch 36/50\n",
      "375/375 [==============================] - 141s 375ms/step - loss: 1.0442 - acc: 0.7069\n",
      "Epoch 37/50\n",
      "375/375 [==============================] - 141s 375ms/step - loss: 1.0626 - acc: 0.7113\n",
      "Epoch 38/50\n",
      "375/375 [==============================] - 141s 376ms/step - loss: 1.0609 - acc: 0.7080\n",
      "Epoch 39/50\n",
      "375/375 [==============================] - 141s 376ms/step - loss: 1.0800 - acc: 0.7056\n",
      "Epoch 40/50\n",
      "375/375 [==============================] - 141s 376ms/step - loss: 1.0624 - acc: 0.7139\n",
      "Epoch 41/50\n",
      "375/375 [==============================] - 141s 375ms/step - loss: 1.0518 - acc: 0.7151\n",
      "Epoch 42/50\n",
      "375/375 [==============================] - 141s 375ms/step - loss: 1.0650 - acc: 0.7119\n",
      "Epoch 43/50\n",
      "375/375 [==============================] - 141s 376ms/step - loss: 1.0655 - acc: 0.7130\n",
      "Epoch 44/50\n",
      "375/375 [==============================] - 141s 376ms/step - loss: 1.0573 - acc: 0.7133\n",
      "Epoch 45/50\n",
      "375/375 [==============================] - 141s 376ms/step - loss: 1.0822 - acc: 0.7124\n",
      "Epoch 46/50\n",
      "375/375 [==============================] - 141s 375ms/step - loss: 1.1031 - acc: 0.7067\n",
      "Epoch 47/50\n",
      "375/375 [==============================] - 141s 376ms/step - loss: 1.0832 - acc: 0.7136\n",
      "Epoch 48/50\n",
      "375/375 [==============================] - 141s 376ms/step - loss: 1.1232 - acc: 0.7105\n",
      "Epoch 49/50\n",
      "375/375 [==============================] - 141s 376ms/step - loss: 1.1293 - acc: 0.7018\n",
      "Epoch 50/50\n",
      "375/375 [==============================] - 141s 376ms/step - loss: 1.0975 - acc: 0.7097\n",
      "\n",
      "Highlighted images training:\n",
      "Epoch 1/33\n",
      "375/375 [==============================] - 109s 291ms/step - loss: 5.1883 - acc: 0.0214\n",
      "Epoch 2/33\n",
      "375/375 [==============================] - 109s 290ms/step - loss: 3.9855 - acc: 0.1281\n",
      "Epoch 3/33\n",
      "375/375 [==============================] - 109s 291ms/step - loss: 2.9199 - acc: 0.2916\n",
      "Epoch 4/33\n",
      "375/375 [==============================] - 109s 290ms/step - loss: 2.1506 - acc: 0.4417\n",
      "Epoch 5/33\n",
      "375/375 [==============================] - 109s 290ms/step - loss: 1.6540 - acc: 0.5528\n",
      "Epoch 6/33\n",
      "375/375 [==============================] - 109s 290ms/step - loss: 1.2959 - acc: 0.6416\n",
      "Epoch 7/33\n",
      "375/375 [==============================] - 109s 290ms/step - loss: 1.0627 - acc: 0.6980\n",
      "Epoch 8/33\n",
      "375/375 [==============================] - 109s 290ms/step - loss: 0.8947 - acc: 0.7405\n",
      "Epoch 9/33\n",
      "375/375 [==============================] - 109s 290ms/step - loss: 0.7647 - acc: 0.7779\n",
      "Epoch 10/33\n",
      "375/375 [==============================] - 109s 290ms/step - loss: 0.6839 - acc: 0.8067\n",
      "Epoch 11/33\n",
      "375/375 [==============================] - 109s 290ms/step - loss: 0.5804 - acc: 0.8284\n",
      "Epoch 12/33\n",
      "375/375 [==============================] - 109s 290ms/step - loss: 0.5118 - acc: 0.8473\n",
      "Epoch 13/33\n",
      "375/375 [==============================] - 109s 290ms/step - loss: 0.4680 - acc: 0.8624\n",
      "Epoch 14/33\n",
      "375/375 [==============================] - 110s 293ms/step - loss: 0.4359 - acc: 0.8701\n",
      "Epoch 15/33\n",
      "375/375 [==============================] - 110s 292ms/step - loss: 0.4021 - acc: 0.8787\n",
      "Epoch 16/33\n",
      "375/375 [==============================] - 110s 293ms/step - loss: 0.3806 - acc: 0.8870\n",
      "Epoch 17/33\n",
      "375/375 [==============================] - 110s 292ms/step - loss: 0.3655 - acc: 0.8945\n",
      "Epoch 18/33\n",
      "375/375 [==============================] - 110s 292ms/step - loss: 0.3253 - acc: 0.9042\n",
      "Epoch 19/33\n",
      "375/375 [==============================] - 110s 292ms/step - loss: 0.3113 - acc: 0.9076\n",
      "Epoch 20/33\n",
      "375/375 [==============================] - 110s 292ms/step - loss: 0.2997 - acc: 0.9101\n",
      "Epoch 21/33\n",
      "375/375 [==============================] - 110s 292ms/step - loss: 0.2814 - acc: 0.9170\n",
      "Epoch 22/33\n",
      "375/375 [==============================] - 110s 294ms/step - loss: 0.2677 - acc: 0.9220\n",
      "Epoch 23/33\n",
      "375/375 [==============================] - 110s 294ms/step - loss: 0.2695 - acc: 0.9219\n",
      "Epoch 24/33\n",
      "375/375 [==============================] - 110s 293ms/step - loss: 0.2612 - acc: 0.9250\n",
      "Epoch 25/33\n",
      "375/375 [==============================] - 109s 291ms/step - loss: 0.2665 - acc: 0.9236\n",
      "Epoch 26/33\n",
      "375/375 [==============================] - 109s 291ms/step - loss: 0.2429 - acc: 0.9308\n",
      "Epoch 27/33\n",
      "375/375 [==============================] - 109s 291ms/step - loss: 0.2416 - acc: 0.9321\n",
      "Epoch 28/33\n",
      "375/375 [==============================] - 109s 291ms/step - loss: 0.2443 - acc: 0.9281\n",
      "Epoch 29/33\n",
      "375/375 [==============================] - 110s 292ms/step - loss: 0.2486 - acc: 0.9284\n",
      "Epoch 30/33\n",
      "375/375 [==============================] - 110s 293ms/step - loss: 0.2548 - acc: 0.9300\n",
      "Epoch 31/33\n",
      "375/375 [==============================] - 110s 293ms/step - loss: 0.2356 - acc: 0.9351\n",
      "Epoch 32/33\n",
      "375/375 [==============================] - 109s 291ms/step - loss: 0.2486 - acc: 0.9322\n",
      "Epoch 33/33\n",
      "375/375 [==============================] - 110s 293ms/step - loss: 0.2359 - acc: 0.9361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faa63ebd4e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 重新建立卷積神經網路\n",
    "model_front = models.Sequential()\n",
    "model_front.add(layers.Conv2D(16, (3, 3), activation = 'relu', input_shape = (image_size, image_size, 3)))\n",
    "model_front.add(layers.MaxPooling2D((2, 2)))\n",
    "model_front.add(Dropout(0.25))\n",
    "model_front.add(layers.Conv2D(32, (3, 3), activation = 'relu'))\n",
    "model_front.add(layers.MaxPooling2D((2, 2)))\n",
    "model_front.add(Dropout(0.25))\n",
    "model_front.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model_front.add(layers.MaxPooling2D((2, 2)))\n",
    "model_front.add(Dropout(0.25))\n",
    "model_front.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model_front.add(layers.MaxPooling2D((2, 2)))\n",
    "model_front.add(Dropout(0.25))\n",
    "model_front.add(layers.Flatten())\n",
    "model_front.add(layers.Dense(128, activation = 'relu'))\n",
    "model_front.add(Dropout(0.5))\n",
    "model_front.add(layers.Dense(250, activation = 'softmax'))\n",
    "\n",
    "model_back = models.Sequential()\n",
    "model_back.add(layers.Conv2D(16, (3, 3), activation = 'relu', input_shape = (image_size, image_size, 3)))\n",
    "model_back.add(layers.MaxPooling2D((2, 2)))\n",
    "model_back.add(Dropout(0.25))\n",
    "model_back.add(layers.Conv2D(32, (3, 3), activation = 'relu'))\n",
    "model_back.add(layers.MaxPooling2D((2, 2)))\n",
    "model_back.add(Dropout(0.25))\n",
    "model_back.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model_back.add(layers.MaxPooling2D((2, 2)))\n",
    "model_back.add(Dropout(0.25))\n",
    "model_back.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model_back.add(layers.MaxPooling2D((2, 2)))\n",
    "model_back.add(Dropout(0.25))\n",
    "model_back.add(layers.Flatten())\n",
    "model_back.add(layers.Dense(128, activation = 'relu'))\n",
    "model_back.add(Dropout(0.5))\n",
    "model_back.add(layers.Dense(250, activation = 'softmax'))\n",
    "\n",
    "model_high = models.Sequential()\n",
    "model_high.add(layers.Conv2D(16, (3, 3), activation = 'relu', input_shape = (image_size, image_size, 3)))\n",
    "model_high.add(layers.MaxPooling2D((2, 2)))\n",
    "model_high.add(Dropout(0.25))\n",
    "model_high.add(layers.Conv2D(32, (3, 3), activation = 'relu'))\n",
    "model_high.add(layers.MaxPooling2D((2, 2)))\n",
    "model_high.add(Dropout(0.25))\n",
    "model_high.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model_high.add(layers.MaxPooling2D((2, 2)))\n",
    "model_high.add(Dropout(0.25))\n",
    "model_high.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model_high.add(layers.MaxPooling2D((2, 2)))\n",
    "model_high.add(Dropout(0.25))\n",
    "model_high.add(layers.Flatten())\n",
    "model_high.add(layers.Dense(128, activation = 'relu'))\n",
    "model_high.add(Dropout(0.5))\n",
    "model_high.add(layers.Dense(250, activation = 'softmax'))\n",
    "\n",
    "# 重新編譯模型\n",
    "model_front.compile(\n",
    "    optimizer = 'rmsprop',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy'])\n",
    "\n",
    "model_back.compile(\n",
    "    optimizer = 'rmsprop',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy'])\n",
    "\n",
    "model_high.compile(\n",
    "    optimizer = 'rmsprop',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy'])\n",
    "\n",
    "# 重新製作數據 Generator\n",
    "data_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "print(\"Status of front images:\")\n",
    "\n",
    "print(\"[Training set]\")\n",
    "\n",
    "front_train_gen = data_generator.flow_from_directory(\n",
    "        front_train_dir,\n",
    "        target_size = (image_size, image_size),\n",
    "        shuffle = True,\n",
    "        seed = 7,\n",
    "        class_mode = 'categorical',\n",
    "        batch_size = 36)\n",
    "\n",
    "print(\"[Testing set]\")\n",
    "\n",
    "front_test_gen = data_generator.flow_from_directory(\n",
    "        front_test_dir,\n",
    "        target_size = (image_size, image_size),\n",
    "        shuffle = True,\n",
    "        seed = 7,\n",
    "        class_mode = 'categorical',\n",
    "        batch_size = 36)\n",
    "\n",
    "print(\"\\nStatus of back images:\")\n",
    "\n",
    "print(\"[Training set]\")\n",
    "\n",
    "back_train_gen = data_generator.flow_from_directory(\n",
    "        back_train_dir,\n",
    "        target_size = (image_size, image_size),\n",
    "        shuffle = True,\n",
    "        seed = 7,\n",
    "        class_mode = 'categorical',\n",
    "        batch_size = 36)\n",
    "\n",
    "print(\"[Testing set]\")\n",
    "\n",
    "back_test_gen = data_generator.flow_from_directory(\n",
    "        back_test_dir,\n",
    "        target_size = (image_size, image_size),\n",
    "        shuffle = True,\n",
    "        seed = 7,\n",
    "        class_mode = 'categorical',\n",
    "        batch_size = 36)\n",
    "\n",
    "print(\"\\nStatus of highlighted images:\")\n",
    "\n",
    "print(\"[Training set]\")\n",
    "\n",
    "high_train_gen = data_generator.flow_from_directory(\n",
    "        high_train_dir,\n",
    "        target_size = (image_size, image_size),\n",
    "        shuffle = True,\n",
    "        seed = 7,\n",
    "        class_mode = 'categorical',\n",
    "        batch_size = 36)\n",
    "\n",
    "print(\"[Testing set]\")\n",
    "\n",
    "high_test_gen = data_generator.flow_from_directory(\n",
    "        high_test_dir,\n",
    "        target_size = (image_size, image_size),\n",
    "        shuffle = True,\n",
    "        seed = 7,\n",
    "        class_mode = 'categorical',\n",
    "        batch_size = 36)\n",
    "\n",
    "# 設定 Callback 函式並在訓練完成時，計算測試資料集的 F1-score\n",
    "test_f1s = []\n",
    "\n",
    "class MetricsFront(Callback):\n",
    "\n",
    "    def __init__(self, test_data = front_test_gen, batch_size = 36):\n",
    "        super().__init__()\n",
    "        self.test_data = test_data\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def on_train_end(self, epoch, logs={}):\n",
    "        batches = len(self.test_data)\n",
    "        total = batches * self.batch_size\n",
    "        \n",
    "        test_pred = np.zeros((total, 250))\n",
    "        test_true = np.zeros((total, 250))\n",
    "        \n",
    "        for batch in range(batches):\n",
    "            xTest, yTest = next(self.test_data)\n",
    "            test_pred[batch * self.batch_size : (batch + 1) * self.batch_size] = np.asarray(self.model.predict(xTest)).round()\n",
    "            test_true[batch * self.batch_size : (batch + 1) * self.batch_size] = yTest\n",
    "            \n",
    "        test_pred = np.squeeze(test_pred)\n",
    "        _test_f1 = f1_score(test_true, test_pred, average = 'micro')\n",
    "        test_f1s.append(_test_f1)\n",
    "        \n",
    "        return\n",
    "    \n",
    "class MetricsBack(Callback):\n",
    "\n",
    "    def __init__(self, test_data = back_test_gen, batch_size = 36):\n",
    "        super().__init__()\n",
    "        self.test_data = test_data\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def on_train_end(self, epoch, logs={}):\n",
    "        batches = len(self.test_data)\n",
    "        total = batches * self.batch_size\n",
    "        \n",
    "        test_pred = np.zeros((total, 250))\n",
    "        test_true = np.zeros((total, 250))\n",
    "        \n",
    "        for batch in range(batches):\n",
    "            xTest, yTest = next(self.test_data)\n",
    "            test_pred[batch * self.batch_size : (batch + 1) * self.batch_size] = np.asarray(self.model.predict(xTest)).round()\n",
    "            test_true[batch * self.batch_size : (batch + 1) * self.batch_size] = yTest\n",
    "            \n",
    "        test_pred = np.squeeze(test_pred)\n",
    "        _test_f1 = f1_score(test_true, test_pred, average = 'micro')\n",
    "        test_f1s.append(_test_f1)\n",
    "        \n",
    "        return\n",
    "    \n",
    "class MetricsHigh(Callback):\n",
    "\n",
    "    def __init__(self, test_data = high_test_gen, batch_size = 36):\n",
    "        super().__init__()\n",
    "        self.test_data = test_data\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def on_train_end(self, epoch, logs={}):\n",
    "        batches = len(self.test_data)\n",
    "        total = batches * self.batch_size\n",
    "        \n",
    "        test_pred = np.zeros((total, 250))\n",
    "        test_true = np.zeros((total, 250))\n",
    "        \n",
    "        for batch in range(batches):\n",
    "            xTest, yTest = next(self.test_data)\n",
    "            test_pred[batch * self.batch_size : (batch + 1) * self.batch_size] = np.asarray(self.model.predict(xTest)).round()\n",
    "            test_true[batch * self.batch_size : (batch + 1) * self.batch_size] = yTest\n",
    "            \n",
    "        test_pred = np.squeeze(test_pred)\n",
    "        _test_f1 = f1_score(test_true, test_pred, average = 'micro')\n",
    "        test_f1s.append(_test_f1)\n",
    "\n",
    "        return\n",
    "    \n",
    "# 重新訓練深度學習網路\n",
    "print(\"\\nFront images training:\")\n",
    "\n",
    "model_front.fit_generator(\n",
    "    front_train_gen,\n",
    "    steps_per_epoch = 375,\n",
    "    epochs = best_front_epochs,\n",
    "    callbacks = [MetricsFront()])\n",
    "\n",
    "print(\"\\nBack images training:\")\n",
    "\n",
    "model_back.fit_generator(\n",
    "    back_train_gen,\n",
    "    steps_per_epoch = 375,\n",
    "    epochs = best_back_epochs,\n",
    "    callbacks = [MetricsBack()])\n",
    "\n",
    "print(\"\\nHighlighted images training:\")\n",
    "\n",
    "model_high.fit_generator(\n",
    "    high_train_gen,\n",
    "    steps_per_epoch = 375,\n",
    "    epochs = best_high_epochs,\n",
    "    callbacks = [MetricsHigh()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 實驗總結"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TESTING RESULT ---\n",
      "[Front]\t\tThe f1-score of front testing set: 48.52%\n",
      "[Back]\t\tThe f1-score of back testing set: 74.38%\n",
      "[Highlighted]\tThe f1-score of highlighted testing set: 98.10%\n"
     ]
    }
   ],
   "source": [
    "print(\"--- TESTING RESULT ---\")\n",
    "print(\"[Front]\\t\\tThe f1-score of front testing set: %.2f%%\"%(test_f1s[0] * 100))\n",
    "print(\"[Back]\\t\\tThe f1-score of back testing set: %.2f%%\"%(test_f1s[1] * 100))\n",
    "print(\"[Highlighted]\\tThe f1-score of highlighted testing set: %.2f%%\"%(test_f1s[2] * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
